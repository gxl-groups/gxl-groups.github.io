---
nav_exclude: true
---

特征响应图组尺寸计算


池化操作

不改变深度信息, 窗口有/没有重叠(这里示例是没有重叠的)
![](https://s2.loli.net/2022/07/04/3WeZdLmjiIN5lGt.png)


## 经典网络分析

### AlexNet

LeNet5
![](https://s2.loli.net/2022/07/04/J6vENXWjTdSCeqY.png)

ImageNet LSVPC大规模视觉识别挑战赛

大数据 显卡(计算设备)

![](https://s2.loli.net/2022/07/04/SL1Itvjem8JXb4H.png)

第一层 conv1: 96个11×11卷积核,步长为4, 没有零填充

问题: 输入:227×227×3 输出:96个55×55×3的特征图(227-11+0)/4+1 总共有96×(11×11×3+1)个参数
![](https://s2.loli.net/2022/07/04/Msrc49Ib8kjt1oC.png)

Max Pool1: 窗口大小为3×3,步长为2.
作用:降低特征图尺寸,对抗轻微的目标偏移带来的影响
输出的尺寸:(55-3)/2+1=27,特征图个数96,没有参数,按照某种固定的模式采样数据.

重叠有助于对抗过拟合

Conc2: 256个5×5卷积核,步长为1,使用零填充p=2

输入: 27×27×96的特征图组
输出: 大小(27-5+2×2)/1+1=27
个数:256
每个卷积核都表示一种局部结构,增加了计院的表述能力记录更多的东西. 堆叠卷积 一个像素点相当于原图50×50

Conv3,Conv4: 384个3×3卷积核步长为1,使用零填充p=1
输入: 13×13×256
输出:13×13×384
没有进行最大池化与局部规划

Conv5: 256个3×3卷积核,步长为1,使用零填充p=1
最大池化层来进一步缩小特征图尺寸6×6×256

第六-八层FC6,FC7,FC8全连接神经网络分类器

重要说明: 用于提取图像特征的卷积层以及用于分类的全连接层是同时学习的

端到端学习

卷积层与全连接层在训练过程中相互影响
![](https://s2.loli.net/2022/07/04/AC5mzGIYHFjOBQ6.png)


![](https://s2.loli.net/2022/07/04/cyYwWNz59s1VXQK.png)


问题: AlexNet卷积层在做什么?

具有语义结构,从数据中习得 卷积核 超集卷积核组 对应特征响应图

![](https://s2.loli.net/2022/07/04/ElbkYU1eBoAHxIL.png)


## ZFNet 
与AlexNet网络结构基本一致

第一个卷积层的卷积核大小改为7×7 感受更细粒度的东西

将第二个第三个卷积层的卷积步长都设置为2 缓慢降低特征图尺寸,提取更多信息

增加了第三第四个卷积层卷积核个数 初步具有语义信息,不再是简单的基元,是基元的组合

![](https://s2.loli.net/2022/07/04/eNKGnFsYA4qzdju.png)


## VGG 
![](https://s2.loli.net/2022/07/04/X7O2KGkYjgRsQrE.png)

用更小的卷积核多次串联 得到更大的感受野

深度更深,非线性更强 网络参数更少

去掉了AlexNet中的局部响应归一化层

19层VGG更深,精度略微提升,但是所需内存更多

VGG16 13个卷积层与3个全连接

分为5段,conv1, conv5, 每一段中卷积层的卷积核个数均相同


所有卷积

![](https://s2.loli.net/2022/07/04/kWrcRYyieDQON1P.png)


小卷积核的优势:
多个小卷积核串联可以得到与大尺寸卷积核相同的感受野

![](https://s2.loli.net/2022/07/04/f4BM92wlhPs8V57.png)

为什么VGG网络前四段,每经过一次池化操作,卷积核个数就增加一倍?

回答:

池化操作有助于减小

![](https://s2.loli.net/2022/07/04/zaNSQR7tDGZLf2y.png)

为什么卷积核个数增加到512后就不再增加了?

VGG证明的结论

1. 深度

2. 小卷积核串联

## GoogLeNet

![](https://s2.loli.net/2022/07/04/Sc3eNfl7ULTxiz6.png)

![](https://s2.loli.net/2022/07/04/7D2cEeZgLWOANCQ.png)

串联结构存在的问题:
后面的卷积层只能处理前层输出的特征图,前层因某些原因(比如感受野限制)丢失重要信息,后层无法找回

解决方案: 每一层尽量保留输入的信号

1×1的卷积 深度通道上的操作,没有改变空间信息,压缩空间信息
3×3 提取大小感受野
3×3 max pooling  

按深度方向做一个拼接
![](https://s2.loli.net/2022/07/04/HAlRadM7TfPhGIE.png)

直接用起来非常慢

![](https://s2.loli.net/2022/07/04/YvPdnBFwTlxWaOc.png)

![](https://s2.loli.net/2022/07/04/NGad5KouBr1vW6w.png)

![](https://s2.loli.net/2022/07/04/kgte1GjKow7WLrn.png)


层数更深, 参数更少, 计算效率更高, 非线性表达能力更强

1×1卷积用来降低深度通道数量

pooling后面的卷积用来压缩通道数量

![](https://s2.loli.net/2022/07/05/ncJvoNlzb82RxqP.png)

1×1卷积进行压缩会损失信息吗?
深度由前一层的深度决定,输出1个特征图

前面的64维是一个非常稀疏的向量,压缩为32维的不会丢失信息
![](https://s2.loli.net/2022/07/05/q7RwzLQ83oTrOe9.png)



## ResNet

不断加深网络,性能是否会一直提升呢?

![](https://s2.loli.net/2022/07/05/Xs7ycWz5vJDZCeN.png)

在训练集上56层的性能也低于20层的.

![image-20220705173839371](https://s2.loli.net/2022/07/05/y62w1oExiPuZIUj.png)
残差模块让前向信息流和反向信息流动更顺畅

![](https://s2.loli.net/2022/07/05/C5ZptkY4Fs8eAPI.png)

残差模块: 恒等映射结构

![](https://s2.loli.net/2022/07/05/mj3kFOBt9q1PWIR.png)

前向信息流可以传递,反向梯度流也可以顺利通过.


第一个1×1降低通道数,第二个升通道

ResNet的结构
有重叠池化


为什么残差网络性能这么好?
![](https://s2.loli.net/2022/07/05/3xqJtQw4godmhAk.png)
最根本原因: 残差网络可以看做是一种集成模型
多个子网络输出求和得到的结果

随意取消一些层,网络的性能不会变差,但是VGG之类的则会降低,后面的依赖于前面的

DenseNet证明ResNet很多冗余无效信息,会拖慢训练的效率


视觉识别任务

分类(不考虑空间位置) 语义分割(像素的类别) 目标检测9多目标 实例分割

语义分割: 给每个像素分配类别标签 不区分实例,只考虑像素类别

语义分割思路: 滑动窗口
问题: 效率太低! 重叠区域的特征反复被计算

