---
layout: default
title: 纹理表示&卷积神经网络
nav_exclude: true
---

# 纹理表示&卷积神经网络

Canny边缘提取

纹理表示

- 规则纹理
- 随机纹理

边缘提取杂乱没法表示纹理
基元组合而来

基于卷积核组的纹理表示方法

利用卷积核组来表示
![](https://s2.loli.net/2022/07/03/z1FKioIb9DUWMkc.png)
一个是边一个是斑点

1. 设计卷积核组
2. 利用卷积核组对图像进行卷积操作获得对应的特征响应图组
3. 利用特征响应图的某种统计信息来表示图像中的纹理

![](https://s2.loli.net/2022/07/03/AQfnZVxdXMCGtHi.png)

将特征响应图展开为向量
![](https://s2.loli.net/2022/07/03/A3TEB5gGa1WfZno.png)

特征图展开为向量的时候保存了原理每个特征响应图的位置信息.
这样的位置信息在纹理分类上没有意义.

纹理分类任务

1. 忽略基元位置 (位置对分类没有影响)
2. 关注出现了哪种纹理基元以及出现的次数

![](https://s2.loli.net/2022/07/03/Sm2O6UgWiJPqHpK.png)


纹理A大量存在y方向的边(图像2)

纹理B大量存在


纹理C大量存在斑点
![](https://s2.loli.net/2022/07/03/gGzIyMZws7ruEBH.png)


设计卷积核组

一个卷积核描述一种信息
每一个卷积核描述一种局部结构

设计重点:
- 类型
- 大小


边缘 高斯一阶偏导
条状 高斯二阶偏导
点状

![](https://s2.loli.net/2022/07/03/4N7hfPEnq1sTdy3.png)

卷积神经网络的卷积层的卷积核是神经网络雪来的,更复杂,效果更好的网络,
卷积网络替换掉设计的卷积核

向量中像素的某个位置的值非常大,表示当前像素存在当前位置卷积核所描述的基元,是一个稀疏向量,只具有几种基元,可以进行压缩表示


全连接神经网络的瓶颈

CIFIA10尺寸32×32×3,3072维,隐层每个神经元权值个数是3072+1.
如果图像大小是200×200×3呢?120000+1个.

边太多,容易过拟合,无法训练.

对已经表示成向量且比较小的有效

![](https://s2.loli.net/2022/07/03/ibY72yK6Blm5Lxc.png)

卷积神经网络的组成
![](https://s2.loli.net/2022/07/03/YAlfcV5hR9Obopj.png)

卷积网络中的卷积核

卷积核:
- 不仅具有宽和高,还具有深度
- 卷积核参数不仅包括


![](https://s2.loli.net/2022/07/03/xshtYDd2Mp5uCrB.png)

特征响应图组深度等于卷积核个数
数据信号的深度应该和输入信号的深度一致
![](https://s2.loli.net/2022/07/03/IN5pmbYoAixZSeP.png)

不同特征响应图反应了输入图像对不同卷积核的响应结果

同一特征响应图不同位置的值表示输入图像上不同位置对同一卷积核的响应结果

注意: 卷积层输入不局限于图像,可以是任意三维数据矩阵;该层的卷积核深度要求与输入的三维矩阵的深度一致

卷积步长
在卷积神经网络中,卷积核可以按照指定的间隔进行卷积操作,这个间隔就是卷积步长.

边界填充
卷积神经网络最常用的填充方式是零值填充
保持输入输出尺寸一致

特征响应图组尺寸计算


池化操作

对每一个特征响应图独立进行,降低特征响应图组中每个特征响应图的宽度和高度,减少后续卷积层的参数的数量,降低资源耗费,进而控制过拟合;看到更大视野的东西(大方差卷积核,看到更粗粒度的东西)

池化操作实例:
池化操作对每一个特征响应图独立进行,不改变深度
对特征图某个区域进行池化操作就是在该区域上指定一个值来代表整个区域


下采样

通常使用池化步长为2
最大池化 Canny非最大化抑制

操作后,特征响应图中的75%的响应信息都丢掉,但不改变特征响应图中的个数.
某个点附近都有某个纹理的结果,选择那个最大的来代表

池化层超参数  

图像增强

1. 翻转
2. 随机缩放 & 抠图
3. 色彩抖动
4. 平移 旋转 拉伸 径向畸变 裁剪
5. 